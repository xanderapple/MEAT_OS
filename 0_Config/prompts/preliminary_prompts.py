from . import mandates

def get_preliminary_prompt(source_filename):
    """
    Generates the prompt for the Sub-Agent to perform preliminary synthesis.
    """
    return f"""
Your task is to generate a comprehensive, multi-perspective preliminary synthesis that captures the raw intellectual energy of the provided input while maintaining strict structural rigor. You must prioritize the user's literal voice and clearly separate their affirmed insights from unconfirmed LLM context.

### INPUT SOURCE
The input content is located in the file: `{source_filename}`
**Action Required:** You MUST use the `read_file` tool to read the contents of this file before proceeding.

{mandates.HIGH_FIDELITY_MANDATE}

{mandates.VOICE_MANDATE}

{mandates.LANGUAGE_MANDATE}

{mandates.INPUT_PROCESSING_MANDATE}

### PART 3: SYNTHESIS EXTRACTION - TWO STREAMS
Once the input is processed/filtered, extract information into two distinct streams:

#### STREAM A: User-Validated Insights (The "ME" Stream)
This captures insights, facts, observations, and motivations directly attributable to or explicitly affirmed by the user.

*   **Key Facts & Beliefs:** Literal extraction of core statements, beliefs, or factual information the user has made or explicitly agreed with. **MUST use First Person ("I").**
*   **Personal Observations & Logic:** Document the user's personal observations, interpretations, or reasoning (e.g., specific metaphors, technical specs, system logic).
*   **Core Motivation & Vibe:** Identify and articulate the user's implicit or explicit motivations, values, or goals (The "Why").
*   **Non-Prescriptive Mandate:** Capture ONLY what the user *has done*, *is doing*, or *explicitly plans to do* (e.g., "I will try X"). Do NOT convert observations into imperative advice or "suggested actions" (e.g., "You should do X") unless the user explicitly framed it as a directive to themselves.

{mandates.TAGGING_MANDATE}

#### STREAM B: Unaffirmed LLM Information (The "LITERATURE" Stream)
This captures information generated by the LLM (me) that was part of the conversation but was NOT explicitly affirmed, validated, or built upon by the user. 

*   **Unconfirmed LLM Insights:** Potentially useful points or analyses made by the LLM that the user did not explicitly validate.
*   **External Context Provided by LLM:** Background, definitions, or tangential information introduced by the LLM.

### PART 4: SELF-CRITIQUE (INTERNAL TURN)
Before final output, perform a brief internal check:
1.  **Summarization Check:** Did I collapse any distinct technical specs or metaphors into a single bullet point? (If yes, expand).
2.  **Voice Check:** Did I use the First Person ("I") for all items in Stream A? (If no, rewrite).
3.  **Leak Check:** Did I include any info from the conversation history that ISN'T in the provided input block? (If yes, remove).

### PART 5: OUTPUT STRUCTURE (STRICT MARKDOWN)
Output the synthesis using this exact Markdown structure:

# Preliminary Synthesis

## STREAM A: User-Validated Insights (The "ME" Stream)

### Key Facts & Beliefs
(Your literal extraction of user's key points. Keep the tone raw and direct. Use "I".)

### Personal Observations & Logic
(How the user sees the problem; their specific reasoning/metaphors/specs.)

### Core Motivation & Vibe
(The "Why" behind the user's actions/preferences.)

## STREAM B: Unaffirmed LLM Information (The "LITERATURE" Stream)

### Unconfirmed LLM Insights
(Summary of LLM insights not affirmed by user.)

### External Context Provided by LLM
(Summary of external context provided by LLM not affirmed by user.)
"""